{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vasanthrohith/Resume_extraction_LangChain/blob/main/App_ResumeExtraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugqfZSUw0bXj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install unstructured\n",
        "!pip install tiktoken\n",
        "!pip install pypdf2\n",
        "!pip install streamlit -q\n",
        "!pip install aspose-words\n",
        "# !pip install faiss-cpu\n",
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0YUpMXX1G-g"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ki1iDOAk2nUM"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Base Code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pflGvW8fjZRU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQLWs1Fm1qnU",
        "outputId": "34953ba8-2a2c-4fe0-842c-7063d8bf3cdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import PyPDF2\n",
        "import os\n",
        "import time\n",
        "import aspose.words as aw\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import VectorDBQA\n",
        "from openai.error import RateLimitError\n",
        "\n",
        "openai_key=\"\"\n",
        "\n",
        "#--------------------Prompt template---------------------------\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "You will be provided with text which are extracted from resume\n",
        "your goal is to extract the below detail from the provided text in the below format:\n",
        "\"Name\" : full name,\n",
        "\"mobile_number\" : number,\n",
        "\"Work_experience\" : experience,\n",
        "\"projects\": projects,\n",
        "\"email_s\": email\n",
        "\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "You should not consider skills, area of interest and extra curricular activities as work experience\n",
        "give a brief details about the work experience\n",
        "if there is no work experience simply mention NA\n",
        "\n",
        "in addition you should predict the gender of that person and mention it as\n",
        "\"gender\": gender\n",
        "\n",
        "refer the below exaple for your work:\n",
        "\"Name\" : surya krishnan,\n",
        "\"mobile_number\" : 9988445568,\n",
        "\"Work_experience\" : 2 years worked at google,\n",
        "\"projects\":'petrofac - product deployment and server management (development,uat and production); prdp - product development and support,\n",
        "\"email\": surya@gmail.com\n",
        "\"gender\": male\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "template_project_qna = \"\"\"\n",
        "\n",
        "Your role is an interviewer\n",
        "\n",
        "You will be provided with a candidate's job profile details as text\n",
        "\n",
        "your task is to:\n",
        "- ask questions only from the projects mentioned on his profile\n",
        "- you have to ask only 8 questions in total, don't ask not more than 8\n",
        "- you should ask those questions from any one project mentiond on his profile\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt=PromptTemplate(input_variables=[\"text\"],\n",
        "                      template=template)\n",
        "\n",
        "prompt_project_qna=PromptTemplate(input_variables=[\"text\"],\n",
        "                                  template=template_project_qna)\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Resume_Extraction\",page_icon=\"üîç\")\n",
        "# st.header(\"Get your resume highlights\")\n",
        "# st.write(\"upload your file\")\n",
        "\n",
        "\n",
        "#--------------------Functions---------------------------\n",
        "\n",
        "\n",
        "def model(openai_key):\n",
        "    llm=OpenAI(temperature=0,openai_api_key=openai_key)\n",
        "    return llm\n",
        "\n",
        "def path():\n",
        "    file_path_=\"\"\n",
        "    #st.write(file_path_)\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        while True:\n",
        "            current_path=os.getcwd()\n",
        "            file_name=\"saved_file.txt\"\n",
        "            file_path=os.path.join(current_path,file_name)\n",
        "            file_path_ = file_path\n",
        "            break\n",
        "    except Exception as e:\n",
        "        path()\n",
        "    return file_path_\n",
        "\n",
        "\n",
        "\n",
        "def file_summary(file_doc):\n",
        "    splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "    docs=splitter.split_documents(file_doc)\n",
        "\n",
        "    summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=False)\n",
        "    summary=summarizer.run(docs)\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "uploaded_file = st.file_uploader(\"\", type=['pdf','docx','doc'],accept_multiple_files=False)\n",
        "\n",
        "menubar=[\"Home\",\"Chat with Resume/CV\",\"Project Q&A\"]\n",
        "choices=st.sidebar.selectbox(\"Menu\",menubar)\n",
        "\n",
        "if \"file_doc\" not in st.session_state:      #\n",
        "    st.session_state.file_doc=None              #=> Help us to store the variable from rerun vanishing\n",
        "if \"summary\" not in st.session_state:       #\n",
        "    st.session_state.summary=None\n",
        "\n",
        "if \"questions\" not in st.session_state:       #\n",
        "    st.session_state.questions=None\n",
        "\n",
        "if \"questions\" not in st.session_state:\n",
        "    st.session_state.user_answer=None\n",
        "\n",
        "#-----------------------------------------Home-----------------------------\n",
        "\n",
        "if choices==\"Home\":\n",
        "\n",
        "    st.subheader(\"Get your resume highlights üîç\")\n",
        "    # uploaded_file = st.file_uploader(\"\", type=['pdf', 'docx', 'doc'])\n",
        "\n",
        "    if uploaded_file:\n",
        "\n",
        "        if uploaded_file.type == \"pdf\":\n",
        "            #st.write(uploaded_file.type)\n",
        "\n",
        "\n",
        "            #--------------------File handling---------------------------\n",
        "            text=\"\"\n",
        "            pdf1 = PyPDF2.PdfReader(uploaded_file)\n",
        "            pages = len(pdf1.pages)\n",
        "            print(\"Number of pages - \",pages)\n",
        "            for i in range(pages):\n",
        "                page=pdf1.pages[i]\n",
        "                text+=page.extract_text()\n",
        "\n",
        "            file_path=path()\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                os.remove(file_path)\n",
        "                with open(\"saved_file.txt\", \"a\") as f:\n",
        "                    f.write(text)\n",
        "                    #st.success(\"File saved successfully.\")\n",
        "\n",
        "            else:\n",
        "                with open(\"saved_file.txt\", \"a\") as f:\n",
        "                    f.write(text)\n",
        "                    #st.success(\"File saved successfully.\")\n",
        "\n",
        "            loader=TextLoader(file_path)\n",
        "            st.session_state.file_doc=loader.load()\n",
        "\n",
        "        else:\n",
        "            uploaded_docx = aw.Document(uploaded_file)\n",
        "            save_docx = uploaded_docx.save(\"output.txt\")\n",
        "            docx_path = os.path.abspath(\"output.txt\")\n",
        "            loader = TextLoader(docx_path)\n",
        "            st.session_state.file_doc = loader.load()\n",
        "\n",
        "\n",
        "        #--------------------Fetching Details---------------------------\n",
        "\n",
        "        llm=model(openai_key)\n",
        "\n",
        "        try:\n",
        "            prompted=prompt.format(text=st.session_state.file_doc)\n",
        "            print(prompted)\n",
        "            try:\n",
        "                result=llm(prompted)\n",
        "                print(result)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"\\n--------------------sumarizing\\n\")\n",
        "            # text_splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "            # file_chunks=text_splitter.split_documents(st.session_state.file_doc)\n",
        "            #\n",
        "            # summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=True)\n",
        "            # file_doc_summary=summarizer.run(file_chunks)\n",
        "            file_doc_summary = file_summary(st.session_state.file_doc)\n",
        "\n",
        "            prompted=prompt.format(text=file_doc_summary)\n",
        "            try:\n",
        "                result=llm(prompted)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details summarizing\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        #st.write(result)\n",
        "\n",
        "        #--------------------Cleaning result---------------------------\n",
        "\n",
        "        try:\n",
        "            splitted=result.split('\\n')\n",
        "            # print(splitted)\n",
        "\n",
        "            #split(\\n)=> to separate every entities in newline so that easily iterated through\n",
        "\n",
        "            dict_entities={}\n",
        "            # using dict to collect all the entities for easy accessibility\n",
        "\n",
        "            for i in splitted:\n",
        "                i=i.lower()\n",
        "                # lower() => to make normalize the text\n",
        "\n",
        "                entities=i.split(':')\n",
        "                # split(':') => to separate label(entities[0]) and values(entities[1])\n",
        "\n",
        "                # print(entities)\n",
        "\n",
        "                #below ladder if will help us to extract every entities and add to dict_entities based on it's label\n",
        "\n",
        "                if \"name\" in entities[0]:\n",
        "                    print(f\"name: {entities[1]}\")\n",
        "                    dict_entities['name']=entities[1].strip()\n",
        "\n",
        "                elif \"mobile_number\" in entities[0]:\n",
        "                    print(f\"mobile_number: {entities[1]}\")\n",
        "                    dict_entities['mobile_number']=entities[1].strip()\n",
        "\n",
        "                elif \"work_experience\" in entities[0]:\n",
        "                    print(f\"Work_experience: {entities[1:]}\")\n",
        "                    dict_entities['Work_experience']=entities[1].strip()\n",
        "\n",
        "                elif \"projects\" in entities[0]:\n",
        "                    print(f\"projects: {entities[1:]}\")\n",
        "                    dict_entities['projects']=entities[1].strip()\n",
        "\n",
        "                elif \"email\" in entities[0]:\n",
        "                    print(f\"email: {entities[1]}\")\n",
        "                    dict_entities['email']=entities[1].strip()\n",
        "\n",
        "                elif \"gender\" in entities[0]:\n",
        "                    print(f\"gender: {entities[1]}\")\n",
        "                    dict_entities['gender']=entities[1].strip()\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        #st.write(dict_entities)\n",
        "        #st.markdown(dict_entities)\n",
        "\n",
        "        #--------------------output to front-end---------------------------\n",
        "\n",
        "            st.markdown(\"### Details\")\n",
        "            col1,col2=st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Name\",value=dict_entities['name'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Phone Number\",value=dict_entities['mobile_number'].replace(\" \",\"\"))\n",
        "\n",
        "\n",
        "            st.text_area(label=\"Work experience\",value=dict_entities['Work_experience'])\n",
        "\n",
        "            st.text_area(label=\"Projects\",value=dict_entities['projects'])\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Email\", value=dict_entities['email'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Gender\", value=dict_entities['gender'])\n",
        "\n",
        "            # --------------------summary of uploaded file---------------------------\n",
        "            st.write(\"\")\n",
        "            st.markdown(\"### Summary\")\n",
        "\n",
        "            st.session_state.summary = file_summary(st.session_state.file_doc)\n",
        "            st.write(st.session_state.summary)\n",
        "        except Exception as e:\n",
        "            print(\"ERROR----------------- Home page - cleaning result/output to front-end/summary of uploaded file\")\n",
        "            print(e)\n",
        "            st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "\n",
        "\n",
        "        # # --------------------Interact with uploaded file---------------------------\n",
        "        #\n",
        "        # st.write(\"\")\n",
        "        # st.markdown(\"Ask a question\")\n",
        "        # # user_question=\"what is the name of the person\"\n",
        "        # user_question = st.text_input(label=\" \")\n",
        "        # if len(user_question) > 2:\n",
        "        #     user_question = str(user_question)\n",
        "        #\n",
        "        #     embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "        #     docsearch = Chroma.from_documents(file_doc, embeddings)\n",
        "        #\n",
        "        #     qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "        #                                     return_source_documents=False)\n",
        "        #     answer = qa({\"query\": user_question})\n",
        "        #\n",
        "        #     st.write(answer['result'])\n",
        "\n",
        "#-----------------------------------------Chat with Resume/CV-----------------------------\n",
        "\n",
        "elif choices==\"Chat with Resume/CV\":\n",
        "    st.markdown(\"### Profile Overview\")\n",
        "    st.write(st.session_state.summary)\n",
        "\n",
        "    # --------------------Interact with uploaded file---------------------------\n",
        "    try:\n",
        "        st.write(\"\")\n",
        "        st.markdown(\"Ask a question\")\n",
        "        # user_question=\"what is the name of the person\"\n",
        "        user_question = st.text_input(label=\" \")\n",
        "        if len(user_question) > 2:\n",
        "            user_question = str(user_question)\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "            docsearch = Chroma.from_documents(st.session_state.file_doc, embeddings)\n",
        "            llm=model(openai_key)\n",
        "\n",
        "\n",
        "            qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "                                                return_source_documents=False)\n",
        "            answer = qa({\"query\": user_question})\n",
        "            st.write(answer['result'])\n",
        "\n",
        "    except RateLimitError as e:\n",
        "        print(\"ERROR----------------- In Interact with uploaded file\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "#-----------------------------------------Project Q&A-----------------------------\n",
        "elif choices==\"Project Q&A\":\n",
        "    st.markdown(\"### Project Q&A\")\n",
        "    prompted = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "\n",
        "    llm = model(openai_key)\n",
        "\n",
        "    # if st.session_state.questions != None:\n",
        "    try:\n",
        "        st.session_state.questions = llm(prompted)\n",
        "    except RateLimitError as e:\n",
        "        print(\"ERROR-----------------In Project Q&A Model\")\n",
        "        st.markdown(\"### Please enter a valid openai API key\")\n",
        "    # print(result)\n",
        "    try:\n",
        "        splitted_questions = st.session_state.questions.split('\\n')\n",
        "        # print(splitted_questions)\n",
        "\n",
        "        dict_project_qna = {}\n",
        "        widget_id = (i for i in range((len(splitted_questions) - 1)))\n",
        "        for i in range(len(splitted_questions)):\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            # print(splitted_questions[i])\n",
        "            # user_answer = input(\"Your answer: \")\n",
        "            # st.write()\n",
        "            st.session_state.user_answer = st.text_input(label=splitted_questions[i], key=f\"key_{i}\")\n",
        "\n",
        "            dict_project_qna[splitted_questions[i]] = st.session_state.user_answer\n",
        "    except Exception as e:\n",
        "        print(\"ERROR----------------- In Project Q&A-------\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "\n",
        "    if st.button(\"Finish\"):\n",
        "        print(dict_project_qna)\n",
        "        print(st.session_state.questions)\n",
        "        # st.success(\"Thank you for the response :-)\")\n",
        "        # st.session_state.questions = None\n",
        "        # questions = st.session_state.questions\n",
        "\n",
        "        with open(\"project_QnA_response\",\"w\") as f:\n",
        "            for i in dict_project_qna:\n",
        "                f.write(f\"\\nquestion {i} | answer {dict_project_qna[i]} \\n\")\n",
        "\n",
        "        thanks_message = st.empty()\n",
        "        thanks_message.success(\"Thanks for your response!\")\n",
        "        st.stop()\n",
        "\n",
        "        # Clear session state\n",
        "        # st.session_state.clear()\n",
        "\n",
        "#     ------------------------------------\n",
        "\n",
        "\n",
        "# Cons:\n",
        "# every time the refresh happening in project qna\n",
        "#\n",
        "# sol:\n",
        "# need to do session state and make everything fetched in home.. like summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version-01 All page uplaod"
      ],
      "metadata": {
        "id": "nMbWHnYw__TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import PyPDF2\n",
        "import os\n",
        "import time\n",
        "import aspose.words as aw\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import VectorDBQA\n",
        "from openai.error import RateLimitError\n",
        "\n",
        "openai_key=\"\"\n",
        "\n",
        "\n",
        "#--------------------Prompt template---------------------------\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "You will be provided with text which are extracted from resume\n",
        "your goal is to extract the below detail from the provided text in the below format:\n",
        "\"Name\" : full name,\n",
        "\"mobile_number\" : number,\n",
        "\"Work_experience\" : experience,\n",
        "\"projects\": projects,\n",
        "\"email_s\": email,\n",
        "\"gender\": gender\n",
        "\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "You should not consider skills, area of interest and extra curricular activities as work experience\n",
        "give a brief details about the work experience\n",
        "if there is no work experience simply mention NA\n",
        "\n",
        "in addition you should predict the gender of that person and mention it as\n",
        "\"gender\": gender\n",
        "\n",
        "refer the below exaple for your work:\n",
        "\"Name\" : surya krishnan,\n",
        "\"mobile_number\" : 9988445568,\n",
        "\"Work_experience\" : 2 years worked at google,\n",
        "\"projects\":'petrofac - product deployment and server management (development,uat and production); prdp - product development and support,\n",
        "\"email\": surya@gmail.com\n",
        "\"gender\": male\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "template_project_qna = \"\"\"\n",
        "\n",
        "Your role is an interviewer\n",
        "\n",
        "You will be provided with a candidate's job profile details as text\n",
        "\n",
        "your task is to:\n",
        "- ask questions only from the projects mentioned on his profile\n",
        "- you have to ask only 8 questions in total, don't ask not more than 8\n",
        "- you should ask those questions from any one project mentiond on his profile\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt=PromptTemplate(input_variables=[\"text\"],\n",
        "                      template=template)\n",
        "\n",
        "prompt_project_qna=PromptTemplate(input_variables=[\"text\"],\n",
        "                                  template=template_project_qna)\n",
        "\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Resume_Extraction\",page_icon=\"üîç\")\n",
        "# st.header(\"Get your resume highlights\")\n",
        "# st.write(\"upload your file\")\n",
        "\n",
        "\n",
        "#--------------------Functions---------------------------\n",
        "\n",
        "\n",
        "def model(openai_key):\n",
        "    try:\n",
        "        llm=OpenAI(temperature=0,openai_api_key=openai_key)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "\n",
        "\n",
        "    return llm\n",
        "\n",
        "def path():\n",
        "    file_path_=\"\"\n",
        "    #st.write(file_path_)\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        while True:\n",
        "            current_path=os.getcwd()\n",
        "            file_name=\"saved_file.txt\"\n",
        "            file_path=os.path.join(current_path,file_name)\n",
        "            file_path_ = file_path\n",
        "            break\n",
        "    except Exception as e:\n",
        "        path()\n",
        "    return file_path_\n",
        "\n",
        "\n",
        "\n",
        "def file_summary(file_doc):\n",
        "    splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "    docs=splitter.split_documents(file_doc)\n",
        "    try:\n",
        "        summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=False)\n",
        "        summary=summarizer.run(docs)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "        st.stop()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "uploaded_file = st.file_uploader(\"\", type=['pdf','docx','doc'],accept_multiple_files=False)\n",
        "\n",
        "menubar=[\"Home\",\"Chat with Resume/CV\",\"Project Q&A\"]\n",
        "choices=st.sidebar.selectbox(\"Menu\",menubar)\n",
        "\n",
        "if \"file_doc\" not in st.session_state:      #\n",
        "    st.session_state.file_doc=None              #=> Help us to store the variable from rerun vanishing\n",
        "\n",
        "if \"result\" not in st.session_state:\n",
        "    st.session_state.result=None\n",
        "\n",
        "if \"summary\" not in st.session_state:       #\n",
        "    st.session_state.summary=None\n",
        "\n",
        "if \"questions\" not in st.session_state:       #\n",
        "    st.session_state.questions=None\n",
        "\n",
        "if \"user_answer\" not in st.session_state:\n",
        "    st.session_state.user_answer=None\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------Home-----------------------------\n",
        "\n",
        "if choices==\"Home\":\n",
        "\n",
        "    st.subheader(\"Get your resume highlights üîç\")\n",
        "    # uploaded_file = st.file_uploader(\"\", type=['pdf', 'docx', 'doc'])\n",
        "\n",
        "    if uploaded_file:\n",
        "\n",
        "        if uploaded_file.type == \"pdf\":\n",
        "            #st.write(uploaded_file.type)\n",
        "\n",
        "\n",
        "            #--------------------File handling---------------------------\n",
        "            text=\"\"\n",
        "            pdf1 = PyPDF2.PdfReader(uploaded_file)\n",
        "            pages = len(pdf1.pages)\n",
        "            print(\"Number of pages - \",pages)\n",
        "            for i in range(pages):\n",
        "                page=pdf1.pages[i]\n",
        "                text+=page.extract_text()\n",
        "\n",
        "            file_path=path()\n",
        "\n",
        "            if os.path.exists(file_path):\n",
        "                os.remove(file_path)\n",
        "                with open(\"saved_file.txt\", \"a\") as f:\n",
        "                    f.write(text)\n",
        "                    #st.success(\"File saved successfully.\")\n",
        "\n",
        "            else:\n",
        "                with open(\"saved_file.txt\", \"a\") as f:\n",
        "                    f.write(text)\n",
        "                    #st.success(\"File saved successfully.\")\n",
        "\n",
        "            loader=TextLoader(file_path)\n",
        "            st.session_state.file_doc=loader.load()\n",
        "\n",
        "        else:\n",
        "            try:\n",
        "                uploaded_docx = aw.Document(uploaded_file)\n",
        "                save_docx = uploaded_docx.save(\"output.txt\")\n",
        "                docx_path = os.path.abspath(\"output.txt\")\n",
        "                loader = TextLoader(docx_path)\n",
        "                st.session_state.file_doc = loader.load()\n",
        "            except Exception as e:\n",
        "                print(e)\n",
        "                st.markdown(\"Please check the uploaded file\")\n",
        "                st.stop()\n",
        "\n",
        "\n",
        "        #--------------------Fetching Details---------------------------\n",
        "\n",
        "        llm=model(openai_key)\n",
        "\n",
        "        try:\n",
        "            prompted=prompt.format(text=st.session_state.file_doc)\n",
        "            print(prompted)\n",
        "            try:\n",
        "                st.session_state.result=llm(prompted)\n",
        "                print(st.session_state.result)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"\\n--------------------sumarizing\\n\")\n",
        "            # text_splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "            # file_chunks=text_splitter.split_documents(st.session_state.file_doc)\n",
        "            #\n",
        "            # summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=True)\n",
        "            # file_doc_summary=summarizer.run(file_chunks)\n",
        "            file_doc_summary = file_summary(st.session_state.file_doc)\n",
        "\n",
        "            prompted=prompt.format(text=file_doc_summary)\n",
        "            try:\n",
        "                result=llm(prompted)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details summarizing\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        #st.write(result)\n",
        "\n",
        "        #--------------------Cleaning result---------------------------\n",
        "\n",
        "        try:\n",
        "            splitted=st.session_state.result.split('\\n')\n",
        "            # print(splitted)\n",
        "\n",
        "            #split(\\n)=> to separate every entities in newline so that easily iterated through\n",
        "\n",
        "            dict_entities={}\n",
        "            # using dict to collect all the entities for easy accessibility\n",
        "\n",
        "            for i in splitted:\n",
        "                i=i.lower()\n",
        "                # lower() => to make normalize the text\n",
        "\n",
        "                entities=i.split(':')\n",
        "                # split(':') => to separate label(entities[0]) and values(entities[1])\n",
        "\n",
        "                # print(entities)\n",
        "\n",
        "                #below ladder if will help us to extract every entities and add to dict_entities based on it's label\n",
        "\n",
        "                if \"name\" in entities[0]:\n",
        "                    print(f\"name: {entities[1]}\")\n",
        "                    dict_entities['name']=entities[1].strip()\n",
        "\n",
        "                elif \"mobile_number\" in entities[0]:\n",
        "                    print(f\"mobile_number: {entities[1]}\")\n",
        "                    dict_entities['mobile_number']=entities[1].strip()\n",
        "\n",
        "                elif \"work_experience\" in entities[0]:\n",
        "                    print(f\"Work_experience: {entities[1:]}\")\n",
        "                    dict_entities['Work_experience']=entities[1].strip()\n",
        "\n",
        "                elif \"projects\" in entities[0]:\n",
        "                    print(f\"projects: {entities[1:]}\")\n",
        "                    dict_entities['projects']=entities[1].strip()\n",
        "\n",
        "                elif \"email\" in entities[0]:\n",
        "                    print(f\"email: {entities[1]}\")\n",
        "                    dict_entities['email']=entities[1].strip()\n",
        "\n",
        "                elif \"gender\" in entities[0]:\n",
        "                    print(f\"gender: {entities[1]}\")\n",
        "                    dict_entities['gender']=entities[1].strip()\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        #st.write(dict_entities)\n",
        "        #st.markdown(dict_entities)\n",
        "\n",
        "        #--------------------output to front-end---------------------------\n",
        "\n",
        "            st.markdown(\"### Details\")\n",
        "            col1,col2=st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Name\",value=dict_entities['name'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Phone Number\",value=dict_entities['mobile_number'].replace(\" \",\"\"))\n",
        "\n",
        "\n",
        "            st.text_area(label=\"Work experience\",value=dict_entities['Work_experience'])\n",
        "\n",
        "            st.text_area(label=\"Projects\",value=dict_entities['projects'])\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Email\", value=dict_entities['email'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Gender\", value=dict_entities['gender'])\n",
        "\n",
        "            # --------------------summary of uploaded file---------------------------\n",
        "            st.write(\"\")\n",
        "            st.markdown(\"### Summary\")\n",
        "\n",
        "            st.session_state.summary = file_summary(st.session_state.file_doc)\n",
        "            st.write(st.session_state.summary)\n",
        "        except Exception as e:\n",
        "            print(\"ERROR----------------- Home page - cleaning result/output to front-end/summary of uploaded file\")\n",
        "            print(e)\n",
        "            st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "            st.stop()\n",
        "\n",
        "        # --------------------Project QnA generation---------------------------\n",
        "\n",
        "        prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "\n",
        "        # llm = model(openai_key)\n",
        "\n",
        "        # if st.session_state.questions != None:\n",
        "        try:\n",
        "            st.session_state.questions = llm(prompted_project_qna)\n",
        "        except RateLimitError as e:\n",
        "            print(\"ERROR-----------------In Project Q&A Model\")\n",
        "            st.markdown(\"### Please enter a valid openai API key\")\n",
        "        # print(st.session_state.questions)\n",
        "\n",
        "\n",
        "\n",
        "        # # --------------------Interact with uploaded file---------------------------\n",
        "        #\n",
        "        # st.write(\"\")\n",
        "        # st.markdown(\"Ask a question\")\n",
        "        # # user_question=\"what is the name of the person\"\n",
        "        # user_question = st.text_input(label=\" \")\n",
        "        # if len(user_question) > 2:\n",
        "        #     user_question = str(user_question)\n",
        "        #\n",
        "        #     embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "        #     docsearch = Chroma.from_documents(file_doc, embeddings)\n",
        "        #\n",
        "        #     qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "        #                                     return_source_documents=False)\n",
        "        #     answer = qa({\"query\": user_question})\n",
        "        #\n",
        "        #     st.write(answer['result'])\n",
        "\n",
        "#-----------------------------------------Chat with Resume/CV-----------------------------\n",
        "\n",
        "elif choices==\"Chat with Resume/CV\":\n",
        "    st.markdown(\"### Profile Overview\")\n",
        "    st.write(st.session_state.summary)\n",
        "\n",
        "    # --------------------Interact with uploaded file---------------------------\n",
        "    try:\n",
        "        st.write(\"\")\n",
        "        st.markdown(\"Ask a question\")\n",
        "        # user_question=\"what is the name of the person\"\n",
        "        user_question = st.text_input(label=\" \")\n",
        "        if len(user_question) > 2:\n",
        "            user_question = str(user_question)\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "            docsearch = Chroma.from_documents(st.session_state.file_doc, embeddings)\n",
        "            llm=model(openai_key)\n",
        "\n",
        "\n",
        "            qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "                                                return_source_documents=False)\n",
        "            answer = qa({\"query\": user_question})\n",
        "            st.write(answer['result'])\n",
        "\n",
        "    except RateLimitError as e:\n",
        "        print(\"ERROR----------------- In Interact with uploaded file\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "#-----------------------------------------Project Q&A-----------------------------\n",
        "elif choices==\"Project Q&A\":\n",
        "    st.markdown(\"### Project Q&A\")\n",
        "    # prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "    #\n",
        "    # llm = model(openai_key)\n",
        "    #\n",
        "    # # if st.session_state.questions != None:\n",
        "    # try:\n",
        "    #     st.session_state.questions = llm(prompted_project_qna)\n",
        "    # except RateLimitError as e:\n",
        "    #     print(\"ERROR-----------------In Project Q&A Model\")\n",
        "    #     st.markdown(\"### Please enter a valid openai API key\")\n",
        "    # print(st.session_state.questions)\n",
        "    try:\n",
        "        splitted_questions = st.session_state.questions.split('\\n')\n",
        "        # print(splitted_questions)\n",
        "\n",
        "        dict_project_qna = {}\n",
        "        widget_id = (i for i in range((len(splitted_questions) - 1)))\n",
        "        for i in range(len(splitted_questions)):\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            # print(splitted_questions[i])\n",
        "            # user_answer = input(\"Your answer: \")\n",
        "            # st.write()\n",
        "            st.session_state.user_answer = st.text_input(label=splitted_questions[i], key=f\"key_{i}\")\n",
        "\n",
        "            dict_project_qna[splitted_questions[i]] = st.session_state.user_answer\n",
        "    except Exception as e:\n",
        "        print(\"ERROR----------------- In Project Q&A-------\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Please check upload your file in Home\")\n",
        "\n",
        "\n",
        "    if st.button(\"Finish\"):\n",
        "        print(dict_project_qna)\n",
        "        print(st.session_state.questions)\n",
        "        # st.success(\"Thank you for the response :-)\")\n",
        "        # st.session_state.questions = None\n",
        "        # questions = st.session_state.questions\n",
        "\n",
        "        with open(\"project_QnA_response\",\"w\") as f:\n",
        "            for i in dict_project_qna:\n",
        "                f.write(f\"\\nquestion {i} | answer {dict_project_qna[i]} \\n\")\n",
        "\n",
        "        thanks_message = st.empty()\n",
        "        thanks_message.success(\"Thanks for your response!\")\n",
        "        # st.stop()\n",
        "\n",
        "        # Clear session state\n",
        "        # st.session_state.clear()\n",
        "\n",
        "#     ------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tb9FWsWQ8Vvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version-02 - Home_upload"
      ],
      "metadata": {
        "id": "6TyjOMfJ_1N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# -> Here the upload widget will be shown only in home\n",
        "\n",
        "# pros:\n",
        "# ->clean view.\n",
        "# ->only home will allow user to upload files\n",
        "#\n",
        "# cons:\n",
        "# -> whenever user jumps to other tabs and come again to home it'll be blank. they need to upload the file again.\n",
        "\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "import PyPDF2\n",
        "import os\n",
        "import time\n",
        "import aspose.words as aw\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import VectorDBQA\n",
        "from openai.error import RateLimitError\n",
        "\n",
        "openai_key=\"\"\n",
        "\n",
        "\n",
        "#--------------------Prompt template---------------------------\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "You will be provided with text which are extracted from resume\n",
        "your goal is to extract the below detail from the provided text in the below format:\n",
        "\"Name\" : full name,\n",
        "\"mobile_number\" : number,\n",
        "\"Work_experience\" : experience,\n",
        "\"projects\": projects,\n",
        "\"email_s\": email,\n",
        "\"gender\": gender\n",
        "\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "You should not consider skills, area of interest and extra curricular activities as work experience\n",
        "give a brief details about the work experience\n",
        "if there is no work experience simply mention NA\n",
        "\n",
        "in addition you should predict the gender of that person and mention it as\n",
        "\"gender\": gender\n",
        "\n",
        "refer the below exaple for your work:\n",
        "\"Name\" : surya krishnan,\n",
        "\"mobile_number\" : 9988445568,\n",
        "\"Work_experience\" : 2 years worked at google,\n",
        "\"projects\":'petrofac - product deployment and server management (development,uat and production); prdp - product development and support,\n",
        "\"email\": surya@gmail.com\n",
        "\"gender\": male\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "template_project_qna = \"\"\"\n",
        "\n",
        "Your role is an interviewer\n",
        "\n",
        "You will be provided with a candidate's job profile details as text\n",
        "\n",
        "your task is to:\n",
        "- ask questions only from the projects mentioned on his profile\n",
        "- you have to ask only 8 questions in total, don't ask not more than 8\n",
        "- you should ask those questions from any one project mentiond on his profile\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt=PromptTemplate(input_variables=[\"text\"],\n",
        "                      template=template)\n",
        "\n",
        "prompt_project_qna=PromptTemplate(input_variables=[\"text\"],\n",
        "                                  template=template_project_qna)\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Resume_Extraction\",page_icon=\"üîç\")\n",
        "# st.header(\"Get your resume highlights\")\n",
        "# st.write(\"upload your file\")\n",
        "\n",
        "#--------------------Functions---------------------------\n",
        "\n",
        "\n",
        "def model(openai_key):\n",
        "    try:\n",
        "        llm=OpenAI(temperature=0,openai_api_key=openai_key)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "\n",
        "\n",
        "    return llm\n",
        "\n",
        "def path():\n",
        "    file_path_=\"\"\n",
        "    #st.write(file_path_)\n",
        "    time.sleep(3)\n",
        "    try:\n",
        "        while True:\n",
        "            current_path=os.getcwd()\n",
        "            file_name=\"saved_file.txt\"\n",
        "            file_path=os.path.join(current_path,file_name)\n",
        "            file_path_ = file_path\n",
        "            break\n",
        "    except Exception as e:\n",
        "        path()\n",
        "    return file_path_\n",
        "\n",
        "\n",
        "def file_summary(file_doc):\n",
        "    splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "    docs=splitter.split_documents(file_doc)\n",
        "    try:\n",
        "        summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=False)\n",
        "        summary=summarizer.run(docs)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "        st.stop()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "# uploaded_file = st.file_uploader(\"\", type=['pdf','docx','doc'],accept_multiple_files=False)\n",
        "\n",
        "menubar=[\"Home\",\"Chat with Resume/CV\",\"Project Q&A\"]\n",
        "choices=st.sidebar.selectbox(\"Menu\",menubar)\n",
        "\n",
        "if \"file_doc\" not in st.session_state:      #\n",
        "    st.session_state.file_doc=None              #=> Help us to store the variable from rerun vanishing\n",
        "\n",
        "if \"result\" not in st.session_state:\n",
        "    st.session_state.result=None\n",
        "\n",
        "if \"summary\" not in st.session_state:       #\n",
        "    st.session_state.summary=None\n",
        "\n",
        "if \"questions\" not in st.session_state:       #\n",
        "    st.session_state.questions=None\n",
        "\n",
        "if \"user_answer\" not in st.session_state:\n",
        "    st.session_state.user_answer=None\n",
        "\n",
        "#-----------------------------------------Home-----------------------------\n",
        "\n",
        "# starting the upload work\n",
        "\n",
        "if choices==\"Home\":\n",
        "\n",
        "    st.subheader(\"Get your resume/CV highlights üîç\")\n",
        "    st.session_state.uploaded_file = st.file_uploader(\"\", type=['pdf', 'docx', 'doc'])\n",
        "\n",
        "    if st.session_state.uploaded_file:\n",
        "\n",
        "        # if st.session_state.uploaded_file.type == \"pdf\":\n",
        "        #     #st.write(uploaded_file.type)\n",
        "        #\n",
        "        #\n",
        "        #     #--------------------File handling---------------------------\n",
        "        #     text=\"\"\n",
        "        #     pdf1 = PyPDF2.PdfReader(st.session_state.uploaded_file)\n",
        "        #     pages = len(pdf1.pages)\n",
        "        #     print(\"Number of pages - \",pages)\n",
        "        #     for i in range(pages):\n",
        "        #         page=pdf1.pages[i]\n",
        "        #         text+=page.extract_text()\n",
        "        #\n",
        "        #     file_path=path()\n",
        "        #\n",
        "        #     if os.path.exists(file_path):\n",
        "        #         os.remove(file_path)\n",
        "        #         with open(\"saved_file.txt\", \"w\") as f:\n",
        "        #             f.write(text)\n",
        "        #             #st.success(\"File saved successfully.\")\n",
        "        #\n",
        "        #     else:\n",
        "        #         with open(\"saved_file.txt\", \"w\") as f:\n",
        "        #             f.write(text)\n",
        "        #             #st.success(\"File saved successfully.\")\n",
        "        #\n",
        "        #     loader=TextLoader(file_path)\n",
        "        #     st.session_state.file_doc=loader.load()\n",
        "        #     # os.remove(file_path)\n",
        "\n",
        "        # else:\n",
        "        try:\n",
        "            # st.write(\"docx/docs\")\n",
        "            # st.write(st.session_state.uploaded_file.type)\n",
        "            print(st.session_state.uploaded_file.type)\n",
        "            uploaded_docx = aw.Document(st.session_state.uploaded_file)\n",
        "            save_docx = uploaded_docx.save(\"output.txt\")\n",
        "            docx_path = os.path.abspath(\"output.txt\")\n",
        "            loader = TextLoader(docx_path)\n",
        "            st.session_state.file_doc = loader.load()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            st.markdown(\"Please check the uploaded file\")\n",
        "            st.stop()\n",
        "\n",
        "\n",
        "        #--------------------Fetching Details---------------------------\n",
        "\n",
        "        llm=model(openai_key)\n",
        "\n",
        "        try:\n",
        "            prompted=prompt.format(text=st.session_state.file_doc)\n",
        "            print(prompted)\n",
        "            try:\n",
        "                st.session_state.result=llm(prompted)\n",
        "                print(st.session_state.result)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"\\n--------------------sumarizing\\n\")\n",
        "            # text_splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "            # file_chunks=text_splitter.split_documents(st.session_state.file_doc)\n",
        "            #\n",
        "            # summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=True)\n",
        "            # file_doc_summary=summarizer.run(file_chunks)\n",
        "            file_doc_summary = file_summary(st.session_state.file_doc)\n",
        "\n",
        "            prompted=prompt.format(text=file_doc_summary)\n",
        "            try:\n",
        "                result=llm(prompted)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details summarizing\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        #st.write(result)\n",
        "\n",
        "        #--------------------Cleaning result---------------------------\n",
        "\n",
        "        try:\n",
        "            splitted=st.session_state.result.split('\\n')\n",
        "            # print(splitted)\n",
        "\n",
        "            #split(\\n)=> to separate every entities in newline so that easily iterated through\n",
        "\n",
        "            st.session_state.dict_entities={}\n",
        "            # using dict to collect all the entities for easy accessibility\n",
        "\n",
        "            for i in splitted:\n",
        "                i=i.lower()\n",
        "                # lower() => to make normalize the text\n",
        "\n",
        "                entities=i.split(':')\n",
        "                # split(':') => to separate label(entities[0]) and values(entities[1])\n",
        "\n",
        "                # print(entities)\n",
        "\n",
        "                #below ladder if will help us to extract every entities and add to dict_entities based on it's label\n",
        "\n",
        "                if \"name\" in entities[0]:\n",
        "                    print(f\"name: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['name']=entities[1].strip()\n",
        "\n",
        "                elif \"mobile_number\" in entities[0]:\n",
        "                    print(f\"mobile_number: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['mobile_number']=entities[1].strip()\n",
        "\n",
        "                elif \"work_experience\" in entities[0]:\n",
        "                    print(f\"Work_experience: {entities[1:]}\")\n",
        "                    st.session_state.dict_entities['Work_experience']=entities[1].strip()\n",
        "\n",
        "                elif \"projects\" in entities[0]:\n",
        "                    print(f\"projects: {entities[1:]}\")\n",
        "                    st.session_state.dict_entities['projects']=entities[1].strip()\n",
        "\n",
        "                elif \"email\" in entities[0]:\n",
        "                    print(f\"email: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['email']=entities[1].strip()\n",
        "\n",
        "                elif \"gender\" in entities[0]:\n",
        "                    print(f\"gender: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['gender']=entities[1].strip()\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        #st.write(dict_entities)\n",
        "        #st.markdown(dict_entities)\n",
        "\n",
        "        #--------------------output to front-end---------------------------\n",
        "\n",
        "            st.markdown(\"### Details\")\n",
        "            col1,col2=st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Name\",value=st.session_state.dict_entities['name'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Phone Number\",value=st.session_state.dict_entities['mobile_number'].replace(\" \",\"\"))\n",
        "\n",
        "\n",
        "            st.text_area(label=\"Work experience\",value=st.session_state.dict_entities['Work_experience'])\n",
        "\n",
        "            st.text_area(label=\"Projects\",value=st.session_state.dict_entities['projects'])\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Email\", value=st.session_state.dict_entities['email'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Gender\", value=st.session_state.dict_entities['gender'])\n",
        "\n",
        "            # --------------------summary of uploaded file---------------------------\n",
        "            st.write(\"\")\n",
        "            st.markdown(\"### Summary\")\n",
        "\n",
        "            st.session_state.summary = file_summary(st.session_state.file_doc)\n",
        "            st.write(st.session_state.summary)\n",
        "        except Exception as e:\n",
        "            print(\"ERROR----------------- Home page - cleaning result/output to front-end/summary of uploaded file\")\n",
        "            print(e)\n",
        "            st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "            st.stop()\n",
        "\n",
        "        # --------------------Project QnA generation---------------------------\n",
        "\n",
        "        prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "\n",
        "        # llm = model(openai_key)\n",
        "\n",
        "        # if st.session_state.questions != None:\n",
        "        try:\n",
        "            st.session_state.questions = llm(prompted_project_qna)\n",
        "        except RateLimitError as e:\n",
        "            print(\"ERROR-----------------In Project Q&A Model\")\n",
        "            st.markdown(\"### Please enter a valid openai API key\")\n",
        "        # print(st.session_state.questions)\n",
        "\n",
        "\n",
        "\n",
        "        # # --------------------Interact with uploaded file---------------------------\n",
        "        #\n",
        "        # st.write(\"\")\n",
        "        # st.markdown(\"Ask a question\")\n",
        "        # # user_question=\"what is the name of the person\"\n",
        "        # user_question = st.text_input(label=\" \")\n",
        "        # if len(user_question) > 2:\n",
        "        #     user_question = str(user_question)\n",
        "        #\n",
        "        #     embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "        #     docsearch = Chroma.from_documents(file_doc, embeddings)\n",
        "        #\n",
        "        #     qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "        #                                     return_source_documents=False)\n",
        "        #     answer = qa({\"query\": user_question})\n",
        "        #\n",
        "        #     st.write(answer['result'])\n",
        "\n",
        "#-----------------------------------------Chat with Resume/CV-----------------------------\n",
        "\n",
        "elif choices==\"Chat with Resume/CV\":\n",
        "    st.markdown(\"### Profile Overview\")\n",
        "    st.write(st.session_state.summary)\n",
        "\n",
        "    # --------------------Interact with uploaded file---------------------------\n",
        "    try:\n",
        "        st.write(\"\")\n",
        "        st.markdown(\"Ask a question\")\n",
        "        # user_question=\"what is the name of the person\"\n",
        "        user_question = st.text_input(label=\" \")\n",
        "        if len(user_question) > 2:\n",
        "            user_question = str(user_question)\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "            docsearch = Chroma.from_documents(st.session_state.file_doc, embeddings)\n",
        "            llm=model(openai_key)\n",
        "\n",
        "\n",
        "            qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "                                                return_source_documents=False)\n",
        "            answer = qa({\"query\": user_question})\n",
        "            st.write(answer['result'])\n",
        "\n",
        "    except RateLimitError as e:\n",
        "        print(\"ERROR----------------- In Interact with uploaded file\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "#-----------------------------------------Project Q&A-----------------------------\n",
        "elif choices==\"Project Q&A\":\n",
        "    st.markdown(\"### Project Q&A\")\n",
        "    # prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "    #\n",
        "    # llm = model(openai_key)\n",
        "    #\n",
        "    # # if st.session_state.questions != None:\n",
        "    # try:\n",
        "    #     st.session_state.questions = llm(prompted_project_qna)\n",
        "    # except RateLimitError as e:\n",
        "    #     print(\"ERROR-----------------In Project Q&A Model\")\n",
        "    #     st.markdown(\"### Please enter a valid openai API key\")\n",
        "    # print(st.session_state.questions)\n",
        "    try:\n",
        "        splitted_questions = st.session_state.questions.split('\\n')\n",
        "        # print(splitted_questions)\n",
        "\n",
        "        dict_project_qna = {}\n",
        "        widget_id = (i for i in range((len(splitted_questions) - 1)))\n",
        "        for i in range(len(splitted_questions)):\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            # print(splitted_questions[i])\n",
        "            # user_answer = input(\"Your answer: \")\n",
        "            # st.write()\n",
        "            st.session_state.user_answer = st.text_input(label=splitted_questions[i], key=f\"key_{i}\")\n",
        "\n",
        "            dict_project_qna[splitted_questions[i]] = st.session_state.user_answer\n",
        "    except Exception as e:\n",
        "        print(\"ERROR----------------- In Project Q&A-------\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Please check upload your file in Home\")\n",
        "\n",
        "\n",
        "    if st.button(\"Finish\"):\n",
        "        print(dict_project_qna)\n",
        "        print(st.session_state.questions)\n",
        "        # st.success(\"Thank you for the response :-)\")\n",
        "        # st.session_state.questions = None\n",
        "        # questions = st.session_state.questions\n",
        "\n",
        "        with open(\"project_QnA_response\",\"w\") as f:\n",
        "            for i in dict_project_qna:\n",
        "                f.write(f\"\\nquestion {i} | answer {dict_project_qna[i]} \\n\")\n",
        "\n",
        "        thanks_message = st.empty()\n",
        "        thanks_message.success(\"Thanks for your response!\")\n",
        "        # st.stop()\n",
        "\n",
        "        # Clear session state\n",
        "        # st.session_state.clear()\n",
        "\n",
        "#     ------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A0rbgxCO_vd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version-03 - +Mock Interview"
      ],
      "metadata": {
        "id": "bVeGxjeRiu9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile app.py\n",
        "\n",
        "# -> Here the upload widget will be shown only in home\n",
        "#Features and changes made:\n",
        "        # -> Added Mock Interview section: we can take interview with Chatopenai based on our profile summary\n",
        "        # -> Changed from markdown to title in all the pages\n",
        "\n",
        "# pros:\n",
        "# ->clean view.\n",
        "# ->only home will allow user to upload files\n",
        "#\n",
        "# cons:\n",
        "# -> whenever user jumps to other tabs and come again to home it'll be blank. they need to upload the file again.\n",
        "\n",
        "\n",
        "#                                           *Pillars*\n",
        "#                                           LangChain\n",
        "#                                           Openai\n",
        "#                                           Streamlit\n",
        "\n",
        "\n",
        "\n",
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "# import PyPDF2\n",
        "import os\n",
        "import time\n",
        "import aspose.words as aw\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain import VectorDBQA\n",
        "from openai.error import RateLimitError\n",
        "from langchain.schema import(\n",
        "    AIMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage\n",
        ")\n",
        "import time\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "openai_key=\"\"\n",
        "\n",
        "\n",
        "#--------------------Prompt template---------------------------\n",
        "\n",
        "\n",
        "template=\"\"\"\n",
        "You will be provided with text which are extracted from resume\n",
        "your goal is to extract the below detail from the provided text in the below format:\n",
        "\"Name\" : full name,\n",
        "\"mobile_number\" : number,\n",
        "\"Work_experience\" : experience,\n",
        "\"projects\": projects,\n",
        "\"email_s\": email,\n",
        "\"gender\": gender\n",
        "\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "You should not consider skills, area of interest and extra curricular activities as work experience\n",
        "give a brief details about the work experience\n",
        "if there is no work experience simply mention NA\n",
        "\n",
        "in addition you should predict the gender of that person and mention it as\n",
        "\"gender\": gender\n",
        "\n",
        "refer the below exaple for your work:\n",
        "\"Name\" : surya krishnan,\n",
        "\"mobile_number\" : 9988445568,\n",
        "\"Work_experience\" : 2 years worked at google,\n",
        "\"projects\":'petrofac - product deployment and server management (development,uat and production); prdp - product development and support,\n",
        "\"email\": surya@gmail.com\n",
        "\"gender\": male\n",
        "if there is any field mentioned above not in text you should simply mention NA\n",
        "\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "template_project_qna = \"\"\"\n",
        "\n",
        "Your role is an interviewer\n",
        "\n",
        "You will be provided with a candidate's job profile details as text\n",
        "\n",
        "your task is to:\n",
        "- ask questions only from the projects mentioned on his profile\n",
        "- you have to ask only 8 questions in total, don't ask not more than 8\n",
        "- you should ask those questions from any one project mentiond on his profile\n",
        "\n",
        "Below is the text:\n",
        "text: {text}\n",
        "\n",
        "Your resopnse:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt=PromptTemplate(input_variables=[\"text\"],\n",
        "                      template=template)\n",
        "\n",
        "prompt_project_qna=PromptTemplate(input_variables=[\"text\"],\n",
        "                                  template=template_project_qna)\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Resume_Extraction\",page_icon=\"üîç\")\n",
        "# st.header(\"Get your resume highlights\")\n",
        "# st.write(\"upload your file\")\n",
        "\n",
        "#--------------------Functions---------------------------\n",
        "\n",
        "\n",
        "def model(openai_key):\n",
        "    try:\n",
        "        llm=OpenAI(temperature=0,openai_api_key=openai_key)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "\n",
        "\n",
        "    return llm\n",
        "\n",
        "\n",
        "def file_summary(file_doc):\n",
        "    splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "    docs=splitter.split_documents(file_doc)\n",
        "    try:\n",
        "        summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=False)\n",
        "        summary=summarizer.run(docs)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        st.write(\"please check your Openai API key and try again\")\n",
        "        st.stop()\n",
        "\n",
        "    return summary\n",
        "\n",
        "\n",
        "\n",
        "menubar=[\"Home\",\"Chat with Resume/CV\",\"Project Q&A\",\"Mock interview\"]\n",
        "choices=st.sidebar.selectbox(\"Menu\",menubar)\n",
        "\n",
        "if \"file_doc\" not in st.session_state:      #\n",
        "    st.session_state.file_doc=None              #=> Help us to store the variable from rerun vanishing\n",
        "\n",
        "if \"result\" not in st.session_state:\n",
        "    st.session_state.result=None\n",
        "\n",
        "if \"summary\" not in st.session_state:       #\n",
        "    st.session_state.summary=None\n",
        "\n",
        "if \"questions\" not in st.session_state:       #\n",
        "    st.session_state.questions=None\n",
        "\n",
        "if \"user_answer\" not in st.session_state:\n",
        "    st.session_state.user_answer=None\n",
        "\n",
        "#-----------------------------------------Home-----------------------------\n",
        "\n",
        "\n",
        "if choices==\"Home\":\n",
        "\n",
        "    st.title(\"Get your resume/CV highlights üîç\")\n",
        "    st.session_state.uploaded_file = st.file_uploader(\"\", type=['pdf', 'docx', 'doc'])\n",
        "\n",
        "    if st.session_state.uploaded_file:\n",
        "\n",
        "        try:\n",
        "            # st.write(\"docx/docs\")\n",
        "            # st.write(st.session_state.uploaded_file.type)\n",
        "            print(st.session_state.uploaded_file.type)\n",
        "            uploaded_docx = aw.Document(st.session_state.uploaded_file)\n",
        "            save_docx = uploaded_docx.save(\"output.txt\")\n",
        "            docx_path = os.path.abspath(\"output.txt\")\n",
        "            loader = TextLoader(docx_path)\n",
        "            st.session_state.file_doc = loader.load()\n",
        "        except Exception as e:\n",
        "            print(e)\n",
        "            st.markdown(\"Please check the uploaded file\")\n",
        "            st.stop()\n",
        "\n",
        "\n",
        "        #--------------------Fetching Details---------------------------\n",
        "\n",
        "        llm=model(openai_key)\n",
        "\n",
        "        try:\n",
        "            prompted=prompt.format(text=st.session_state.file_doc)\n",
        "            print(prompted)\n",
        "\n",
        "            try:\n",
        "                st.session_state.result=llm(prompted)\n",
        "                print(st.session_state.result)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(\"\\n--------------------sumarizing\\n\")\n",
        "            # text_splitter=RecursiveCharacterTextSplitter(chunk_size=2000,chunk_overlap=0)\n",
        "            # file_chunks=text_splitter.split_documents(st.session_state.file_doc)\n",
        "            #\n",
        "            # summarizer=load_summarize_chain(llm,chain_type=\"map_reduce\",verbose=True)\n",
        "            # file_doc_summary=summarizer.run(file_chunks)\n",
        "            file_doc_summary = file_summary(st.session_state.file_doc)\n",
        "\n",
        "            prompted=prompt.format(text=file_doc_summary)\n",
        "            try:\n",
        "                result=llm(prompted)\n",
        "            except RateLimitError as e:\n",
        "                print(\"ERROR----------------- In Fetching Details summarizing\")\n",
        "                print(e)\n",
        "                st.markdown(\"### Please check your openai API key\")\n",
        "\n",
        "\n",
        "        #st.write(result)\n",
        "\n",
        "        #--------------------Cleaning result---------------------------\n",
        "\n",
        "        try:\n",
        "            splitted=st.session_state.result.split('\\n')\n",
        "            # print(splitted)\n",
        "\n",
        "            #split(\\n)=> to separate every entities in newline so that easily iterated through\n",
        "\n",
        "            st.session_state.dict_entities={}\n",
        "            # using dict to collect all the entities for easy accessibility\n",
        "\n",
        "            for i in splitted:\n",
        "                i=i.lower()\n",
        "                # lower() => to make normalize the text\n",
        "\n",
        "                entities=i.split(':')\n",
        "                # split(':') => to separate label(entities[0]) and values(entities[1])\n",
        "\n",
        "                # print(entities)\n",
        "\n",
        "                #below ladder if will help us to extract every entities and add to dict_entities based on it's label\n",
        "\n",
        "                if \"name\" in entities[0]:\n",
        "                    print(f\"name: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['name']=entities[1].strip()\n",
        "\n",
        "                elif \"mobile_number\" in entities[0]:\n",
        "                    print(f\"mobile_number: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['mobile_number']=entities[1].strip()\n",
        "\n",
        "                elif \"work_experience\" in entities[0]:\n",
        "                    print(f\"Work_experience: {entities[1:]}\")\n",
        "                    st.session_state.dict_entities['Work_experience']=entities[1].strip()\n",
        "\n",
        "                elif \"projects\" in entities[0]:\n",
        "                    print(f\"projects: {entities[1:]}\")\n",
        "                    st.session_state.dict_entities['projects']=entities[1].strip()\n",
        "\n",
        "                elif \"email\" in entities[0]:\n",
        "                    print(f\"email: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['email']=entities[1].strip()\n",
        "\n",
        "                elif \"gender\" in entities[0]:\n",
        "                    print(f\"gender: {entities[1]}\")\n",
        "                    st.session_state.dict_entities['gender']=entities[1].strip()\n",
        "\n",
        "                else:\n",
        "                    continue\n",
        "\n",
        "        #st.write(dict_entities)\n",
        "        #st.markdown(dict_entities)\n",
        "\n",
        "        #--------------------output to front-end---------------------------\n",
        "\n",
        "            st.markdown(\"### Details\")\n",
        "            col1,col2=st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Name\",value=st.session_state.dict_entities['name'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Phone Number\",value=st.session_state.dict_entities['mobile_number'].replace(\" \",\"\"))\n",
        "\n",
        "\n",
        "            st.text_area(label=\"Work experience\",value=st.session_state.dict_entities['Work_experience'])\n",
        "\n",
        "            st.text_area(label=\"Projects\",value=st.session_state.dict_entities['projects'])\n",
        "            col1, col2 = st.columns(2)\n",
        "            with col1:\n",
        "                # st.markdown(\"**Number of pages**\")\n",
        "                st.text_input(label=\"Email\", value=st.session_state.dict_entities['email'])\n",
        "            with col2:\n",
        "                st.text_input(label=\"Gender\", value=st.session_state.dict_entities['gender'])\n",
        "\n",
        "            # --------------------summary of uploaded file---------------------------\n",
        "            st.write(\"\")\n",
        "            st.markdown(\"### Summary\")\n",
        "\n",
        "            st.session_state.summary = file_summary(st.session_state.file_doc)\n",
        "            st.write(st.session_state.summary)\n",
        "        except Exception as e:\n",
        "            print(\"ERROR----------------- Home page - cleaning result/output to front-end/summary of uploaded file\")\n",
        "            print(e)\n",
        "            st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "            st.stop()\n",
        "\n",
        "        # --------------------Project QnA generation---------------------------\n",
        "\n",
        "        prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "\n",
        "        # if st.session_state.questions != None:\n",
        "        try:\n",
        "            st.session_state.questions = llm(prompted_project_qna)\n",
        "        except RateLimitError as e:\n",
        "            print(\"ERROR-----------------In Project Q&A Model\")\n",
        "            st.markdown(\"### Please enter a valid openai API key\")\n",
        "        # print(st.session_state.questions)\n",
        "\n",
        "\n",
        "\n",
        "#-----------------------------------------Chat with Resume/CV-----------------------------\n",
        "\n",
        "elif choices==\"Chat with Resume/CV\":\n",
        "    st.title(\"Profile Overview\")\n",
        "    st.write(st.session_state.summary)\n",
        "\n",
        "    # --------------------Interact with uploaded file---------------------------\n",
        "    try:\n",
        "        st.write(\"\")\n",
        "        st.markdown(\"Ask a question\")\n",
        "        # user_question=\"what is the name of the person\"\n",
        "        user_question = st.text_input(label=\" \")\n",
        "        if len(user_question) > 2:\n",
        "            user_question = str(user_question)\n",
        "\n",
        "            embeddings = OpenAIEmbeddings(openai_api_key=openai_key)\n",
        "            docsearch = Chroma.from_documents(st.session_state.file_doc, embeddings)\n",
        "            llm=model(openai_key)\n",
        "\n",
        "\n",
        "            qa = VectorDBQA.from_chain_type(llm=llm, chain_type=\"stuff\", vectorstore=docsearch,\n",
        "                                                return_source_documents=False)\n",
        "            answer = qa({\"query\": user_question})\n",
        "            st.write(answer['result'])\n",
        "\n",
        "    except RateLimitError as e:\n",
        "        print(\"ERROR----------------- In Interact with uploaded file\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Oops! Something went wrong, please try again\")\n",
        "\n",
        "#-----------------------------------------Project Q&A-----------------------------\n",
        "elif choices==\"Project Q&A\":\n",
        "    st.title(\"Project Q&A\")\n",
        "    # prompted_project_qna = prompt_project_qna.format(text=st.session_state.file_doc)\n",
        "    #\n",
        "    # llm = model(openai_key)\n",
        "    #\n",
        "    # # if st.session_state.questions != None:\n",
        "    # try:\n",
        "    #     st.session_state.questions = llm(prompted_project_qna)\n",
        "    # except RateLimitError as e:\n",
        "    #     print(\"ERROR-----------------In Project Q&A Model\")\n",
        "    #     st.markdown(\"### Please enter a valid openai API key\")\n",
        "    # print(st.session_state.questions)\n",
        "    try:\n",
        "        splitted_questions = st.session_state.questions.split('\\n')\n",
        "        # print(splitted_questions)\n",
        "\n",
        "        dict_project_qna = {}\n",
        "        widget_id = (i for i in range((len(splitted_questions) - 1)))\n",
        "\n",
        "        for i in range(len(splitted_questions)):\n",
        "            if i == 0:\n",
        "                continue\n",
        "\n",
        "            # print(splitted_questions[i])\n",
        "            # user_answer = input(\"Your answer: \")\n",
        "            # st.write()\n",
        "            st.session_state.user_answer = st.text_input(label=f\"{splitted_questions[i]}\", key=f\"key_{i}\")\n",
        "            # print(splitted_questions[i])\n",
        "            dict_project_qna[splitted_questions[i]] = st.session_state.user_answer\n",
        "    except Exception as e:\n",
        "        print(\"ERROR----------------- In Project Q&A-------\")\n",
        "        print(e)\n",
        "        st.markdown(\"### Please check upload your file in Home\")\n",
        "\n",
        "\n",
        "    if st.button(\"Finish\"):\n",
        "        print(dict_project_qna)\n",
        "        print(st.session_state.questions)\n",
        "        # st.success(\"Thank you for the response :-)\")\n",
        "        # st.session_state.questions = None\n",
        "        # questions = st.session_state.questions\n",
        "\n",
        "        with open(\"project_QnA_response\",\"w\") as f:\n",
        "            for i in dict_project_qna:\n",
        "                f.write(f\"\\nquestion {i} | answer: {dict_project_qna[i]} \\n\")\n",
        "\n",
        "        thanks_message = st.empty()\n",
        "        thanks_message.success(\"Thanks for your response!\")\n",
        "        # st.stop()\n",
        "\n",
        "        # Clear session state\n",
        "        # st.session_state.clear()\n",
        "\n",
        "#     ------------------------------------\n",
        "elif choices==\"Mock interview\":\n",
        "    st.title(\"Mock Interview\")\n",
        "    st.write(\"Note: This mock interview will be conducted based on your profile summary\")\n",
        "    # st.write(\"Enter 'end_interview' to finish the interview \")\n",
        "    # st.write(st.session_state.summary)\n",
        "    profile_summary=st.session_state.summary\n",
        "    if profile_summary!=\"\":\n",
        "        # st.write(st.session_state.summary)\n",
        "        model = ChatOpenAI(temperature=0.2, openai_api_key=openai_key)\n",
        "        message = [SystemMessage(\n",
        "            content=f\"you role is an interviwer. you have to ask questions based on the persons profile summary.you have to ask one question at a time. profile summary: {profile_summary}\"),\n",
        "                   HumanMessage(content=\"Hi\"),\n",
        "                   AIMessage(content=\"Hi welcome to the interview\"), ]\n",
        "\n",
        "\n",
        "        # Interview_part----------------------------\n",
        "        # time.sleep(4)\n",
        "        # user_inp = input(\"User : \")\n",
        "        user_inp=st.text_input(label=\"You:\")\n",
        "        if user_inp !=\"\":\n",
        "            message.append(HumanMessage(content=user_inp))\n",
        "            result = model(message)\n",
        "            # print(\"AI :\",result.content)\n",
        "            st.markdown(\"#### Interviewer: \")\n",
        "            st.write(f\"{result.content}\")\n",
        "            ai_msg = result.content\n",
        "            message.append(AIMessage(content=ai_msg))\n",
        "        else:\n",
        "            st.markdown(\"#### Interviewer: \")\n",
        "            st.write(\"Let's get started\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lrrih9EviyPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rough use cell"
      ],
      "metadata": {
        "id": "sTMREYA96knR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vv4eHv4bz9_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RAKfz8h1rAL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18a24da5-5deb-4d2c-d243-fa3ed49f620f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.91.1.38"
          ]
        }
      ],
      "source": [
        "!curl ifconfig.me"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkYM1jhK2t4t"
      },
      "source": [
        "# Tunnel Opener"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pVI6qZK2VaU"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "nMbWHnYw__TM",
        "6TyjOMfJ_1N9",
        "bVeGxjeRiu9F"
      ],
      "authorship_tag": "ABX9TyOQqUy3X5/9+sCS6MVniJ4y",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}